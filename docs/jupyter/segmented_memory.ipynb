{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Segmented memory (Classifier)**\n",
    "\n",
    "This module is not included the HTM theory it just popped up as I was implementing the Temporal memory. \n",
    "\n",
    "We said CC can be implemented as a 3D array with a shape **( num-of-segments, num-of-mCols, nbits-per-iSDP )**. Segmented memory is the same **shape = (nsegs,rows,isdp)**.\n",
    "\n",
    "Because this module is used to implement TM it accepts two inputs /*In TM case we store transitions, S1 => S2*/.\n",
    "So If we exclude the **time** component from the equation, the *transition* becomes a *classification*.\n",
    "\n",
    "We get two birds with one stone :)\n",
    "\n",
    "Input one in this case is the predictor(**P0**) and two the predicted(**P1**).\n",
    "\n",
    "**The update** works by first figuring out which segment to use first dimension ... later on this.\n",
    "\n",
    "Then use P1 to find indexes of the rows /second dimension/ where to store the P0 pattern /third dimension/. \n",
    "\n",
    "**The prediction** on the other hand works by comparing P0 to every row and every segment and calculating the similarity, then doing a sum across the rows and finally picking 2% of the row-indexes with the biggest sum. The so called Winners-Take-All algorithm.\n",
    "This then becomes the prediction.\n",
    "\n",
    "Now about the segment selection mechanism.\n",
    "\n",
    "Originally all segments are empty, so in this case we pick one at random and store the iSDP.\n",
    "If on the other hand all segments are full, we pick the most similar, \"thin\" the segment-iSDP with the data-iSDP and store the result back.\n",
    "\n",
    "     segs[seg,row,:] = isdp.thin(isdp.union(segs[seg,row,:], input_data), nbits=40)\n",
    "\n",
    "Later in comparison stage all the rules of how similarity on thinned vectors degrade apply.\n",
    " \n",
    "It is equally easy instead of THINNING to use UNION, but this would not preserve sparsity and because we use iSDP, rather than binary SDP it will require us to increase the size of the 3rd dimension.\n",
    "Even then we have to do thinning but at increased number of 'bits' i.e. lower sparsity (higher density).\n",
    "The code change to do that is easy if we need it.\n",
    "Let say the UNION should be allowed to grow to twice the current sparsity of 40bits i.e. 80\n",
    "\n",
    "     segs[seg,row,:] = isdp.thin(isdp.union(segs[seg,row,:], input_data), nbits=80)\n",
    "\n",
    "It is better instead to add more segments, at least logically it seems so, haven't tested it. \n",
    "\n",
    "At the end of the day, SegmentedMemory is defacto a CLASSIFIER.\n",
    "\n",
    "> **This is still research project and I've done limited testing and everything. Keep this in mind.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend(['../../ilib'])\n",
    "from isegmented_memory import *\n",
    "from ilexicon import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize = 500; spa = 0.02\n",
    "x = iLexicon(vsize=vsize,spaOnbits=spa)\n",
    "segm = iSegmentedMemory(shape=(5,vsize,spa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate symbols from 'a' to 'z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.az()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One shot learning ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\n",
      "z\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "segm.learn(data=x.a, pred=x.z)\n",
    "segm.learn(data=x.b, pred=x.z)\n",
    "segm.learn(data=x.c, pred=x.z)\n",
    "\n",
    "print x.best_match(segm.predict(x.a))\n",
    "print x.bm(segm.predict(x.b))\n",
    "print x.bm(segm.predict(x.c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the case of different symbols predicting same symbol, seems to work ;)\n",
    "\n",
    "Next lets try one symbol predicting different results. As expected the prediction would vary and will depend on how the thinning worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "['y', 'x', 'z']\n"
     ]
    }
   ],
   "source": [
    "segm.learn(data=x.d, pred=x.z)\n",
    "segm.learn(data=x.d, pred=x.y)\n",
    "segm.learn(data=x.d, pred=x.x)\n",
    "\n",
    "print x.bm(segm.predict(x.d))\n",
    "print x.best_top(segm.predict(x.d), topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also predict top-n best candidates.\n",
    "\n",
    "Finally can we predict \"ourselves\", seems so :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    }
   ],
   "source": [
    "segm.learn(data=x.f, pred=x.f)\n",
    "print x.bm(segm.predict(x.f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we did not train for something we will get random result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', 'z', 'z', 'y', 'z', 'f', 'x', 'z', 'z', 'z', 'z', 'f', 'f', 'z', 'z', 'x', 'z', 'x', 'z', 'x', 'z', 'x', 'x', 'x', 'z', 'x']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.bm(segm.predict(x[sym])) for sym in string.ascii_lowercase ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0009 :   *   d0017 c0044   *   a0008\n",
      "0031 :   *     *     *   d0037   *  \n",
      "0055 : d0029   *     *   a0008   *  \n",
      "0064 :   *     *     *     *   d0037\n",
      "0076 :   *     *     *     *   d0037\n",
      "0077 :   *     *     *   f0077   *  \n",
      "0079 :   *     *     *     *   f0077\n",
      "0084 : f0077   *     *     *     *  \n",
      "0086 :   *     *     *     *   f0077\n",
      "0093 :   *     *     *     *   d0037\n",
      "0100 :   *     *     *     *   d0037\n",
      "0121 :   *   c0044 b0017 d0037 a0008\n",
      "0145 : f0077   *     *     *     *  \n",
      "0162 :   *     *     *     *   d0037\n",
      "0164 :   *     *     *   f0077   *  \n",
      "0170 :   *     *     *   d0037   *  \n",
      "0180 : f0077   *     *     *     *  \n",
      "0187 :   *     *     *     *   f0077\n",
      "0203 :   *     *     *   c0037 b0017\n",
      "0237 :   *     *   d0037   *     *  \n",
      "0246 : a0008 c0044   *     *   b0017\n",
      "0254 :   *     *   d0037   *     *  \n",
      "0267 :   *     *     *   d0037   *  \n",
      "0273 :   *   d0037   *     *     *  \n",
      "0290 :   *     *     *     *   d0037\n",
      "0298 :   *     *     *     *   d0037\n",
      "0313 :   *   c0037 a0008   *     *  \n",
      "0334 : d0037 c0044 a0008   *   b0017\n",
      "0338 :   *     *   f0077   *     *  \n",
      "0355 :   *     *     *     *   d0037\n",
      "0374 :   *   d0037   *     *     *  \n",
      "0375 :   *     *     *     *   d0037\n",
      "0399 : d0037   *     *     *     *  \n",
      "0406 : f0077   *     *     *     *  \n",
      "0407 : b0044   *   d0037 a0008   *  \n",
      "0426 :   *   b0029   *     *   a0008\n",
      "0427 :   *     *   d0037   *     *  \n",
      "0448 :   *   a0008 c0044 b0017   *  \n",
      "0472 :   *   d0037   *     *     *  \n",
      "0493 :   *   d0037   *     *     *  \n",
      "\n",
      "40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print segm.mem_map(segs=[0,1,2,3,4],lex=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit\n",
      "fruit\n",
      "unknown\n"
     ]
    }
   ],
   "source": [
    "x.add_items(['apple','orange','tomato', 'fruit', 'vegie', 'chair','table','unknown'])\n",
    "segm.learn(data=x.apple, pred=x.fruit)\n",
    "segm.learn(data=x.orange, pred=x.fruit)\n",
    "segm.learn(data=x.chair, pred=x.unknown)\n",
    "\n",
    "print x.best_match(segm.predict(x.apple))\n",
    "print x.bm(segm.predict(x.orange))\n",
    "print x.bm(segm.predict(x.chair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seg-Shape (segs,vsize,bits) : (5, 500, 10), Segments : 5\n",
      "Sparsity/bits: 0.02/10\n",
      "Match-thresh: 0.1, vsize: 500\n",
      "Mem: 0.05 MB, used:3%/840, total:25000\n",
      "Capacity: ~250 patterns, pat/mem:5242.88\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "print segm.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
